{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "random_state = 42"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas._libs.parsers import k\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_6260\\3205523321.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  mvp_stats_2b = pd.read_csv(\"datasets/player_mvp_stats.csv\", ';')\n",
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_6260\\3205523321.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  nicknames_df = pd.read_csv(\"datasets/nicknames.csv\", ';')\n",
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_6260\\3205523321.py:4: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  teams_2b = pd.read_csv(\"datasets/teams.csv\", ';')\n"
     ]
    }
   ],
   "source": [
    "mvp_stats_2b = pd.read_csv(\"datasets/player_mvp_stats.csv\", ';')\n",
    "nicknames_df = pd.read_csv(\"datasets/nicknames.csv\", ';')\n",
    "salaries_2b = pd.read_csv(\"datasets/salaries.csv\")\n",
    "teams_2b = pd.read_csv(\"datasets/teams.csv\", ';')\n",
    "us_inflation_2b = pd.read_csv(\"datasets/US CPI.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Preprocess dan merge beberapa dataset menjadi satu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "def dataframe_to_dict(nicknames_df, key_column_name='Name', value_column_name='Abbreviation'):\n",
    "    keys = nicknames_df[key_column_name]\n",
    "    values = nicknames_df[value_column_name]\n",
    "    return dict(zip(keys, values))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "def cleaning_teamsdf_removeUnimportantRows(teams_2b):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    important_rows = ~teams_2b.W.str.contains(\"Division\")\n",
    "    return teams_2b[important_rows]\n",
    "\n",
    "def cleaning_teamsdf_convertStripToNan(teams_2b):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b.GB = teams_2b.GB.replace(\"â€”\", np.NAN)\n",
    "    return teams_2b\n",
    "\n",
    "def cleaning_teamsdf_convertToAppropriateDatatype(teams_2b):\n",
    "    \"\"\"\n",
    "    preconditions:\n",
    "        cleaning_teamsdf_removeUnimportantRows\n",
    "         cleaning_teamsdf_convertStripToNan\n",
    "    \"\"\"\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b.W = pd.to_numeric(teams_2b.W)\n",
    "    teams_2b.L = pd.to_numeric(teams_2b.L)\n",
    "    teams_2b['W/L%'] = pd.to_numeric(teams_2b['W/L%'])\n",
    "    teams_2b.GB = pd.to_numeric(teams_2b.GB)\n",
    "    teams_2b['PS/G'] = pd.to_numeric(teams_2b['PS/G'])\n",
    "    teams_2b['PA/G'] = pd.to_numeric(teams_2b['PA/G'])\n",
    "    teams_2b.SRS = pd.to_numeric(teams_2b.SRS)\n",
    "    return teams_2b\n",
    "\n",
    "def cleaning_anyDf_removeStarInTeamName(teams_2b, column_name='Team'):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b[column_name] = teams_2b[column_name].str.replace('*', '')\n",
    "    return teams_2b\n",
    "\n",
    "\n",
    "def cleaning_anyDf_convertTeamNamesToItsAbbrev(teams_2b, nicknames_df, column_name='Team'):\n",
    "    \"\"\"\n",
    "    precondition:\n",
    "        teams df:\n",
    "            cleaning_anyDf_removeStarInTeamName\n",
    "    \"\"\"\n",
    "    nicknames_df = nicknames_df.copy()\n",
    "    teams_2b = teams_2b.copy()\n",
    "\n",
    "    nicknames_df = nicknames_df.drop_duplicates(subset='Name', keep='first')\n",
    "    mapping = dataframe_to_dict(nicknames_df)\n",
    "    mapping |= dataframe_to_dict(nicknames_df, 'Abbreviation', 'Abbreviation')\n",
    "\n",
    "    teams_2b[column_name] = list(map(\n",
    "        lambda x: mapping[x],\n",
    "        teams_2b[column_name]\n",
    "    ))\n",
    "    return teams_2b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_6260\\1280597476.py:29: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  teams_2b[column_name] = teams_2b[column_name].str.replace('*', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": "       W   L   W/L%    GB   PS/G   PA/G   SRS  Year Team\n0     56  26  683.0   NaN  111.5  105.7  5.22  1991  BOS\n1     44  38  537.0  12.0  105.4  105.6 -0.39  1991  PHI\n2     39  43  476.0  17.0  103.1  103.3 -0.43  1991  NYK\n3     30  52  366.0  26.0  101.4  106.4 -4.84  1991  WSB\n4     26  56  317.0  30.0  102.9  107.5 -4.53  1991  NJN\n...   ..  ..    ...   ...    ...    ...   ...   ...  ...\n1028  42  30  583.0   NaN  112.4  110.2  2.26  2021  DAL\n1029  38  34  528.0   4.0  113.3  112.3  1.07  2021  MEM\n1030  33  39  458.0   9.0  111.1  112.8 -1.58  2021  SAS\n1031  31  41  431.0  11.0  114.6  114.9 -0.20  2021  NOP\n1032  17  55  236.0  25.0  108.8  116.7 -7.50  2021  HOU\n\n[906 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n      <th>Year</th>\n      <th>Team</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>26</td>\n      <td>683.0</td>\n      <td>NaN</td>\n      <td>111.5</td>\n      <td>105.7</td>\n      <td>5.22</td>\n      <td>1991</td>\n      <td>BOS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44</td>\n      <td>38</td>\n      <td>537.0</td>\n      <td>12.0</td>\n      <td>105.4</td>\n      <td>105.6</td>\n      <td>-0.39</td>\n      <td>1991</td>\n      <td>PHI</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39</td>\n      <td>43</td>\n      <td>476.0</td>\n      <td>17.0</td>\n      <td>103.1</td>\n      <td>103.3</td>\n      <td>-0.43</td>\n      <td>1991</td>\n      <td>NYK</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>52</td>\n      <td>366.0</td>\n      <td>26.0</td>\n      <td>101.4</td>\n      <td>106.4</td>\n      <td>-4.84</td>\n      <td>1991</td>\n      <td>WSB</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26</td>\n      <td>56</td>\n      <td>317.0</td>\n      <td>30.0</td>\n      <td>102.9</td>\n      <td>107.5</td>\n      <td>-4.53</td>\n      <td>1991</td>\n      <td>NJN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1028</th>\n      <td>42</td>\n      <td>30</td>\n      <td>583.0</td>\n      <td>NaN</td>\n      <td>112.4</td>\n      <td>110.2</td>\n      <td>2.26</td>\n      <td>2021</td>\n      <td>DAL</td>\n    </tr>\n    <tr>\n      <th>1029</th>\n      <td>38</td>\n      <td>34</td>\n      <td>528.0</td>\n      <td>4.0</td>\n      <td>113.3</td>\n      <td>112.3</td>\n      <td>1.07</td>\n      <td>2021</td>\n      <td>MEM</td>\n    </tr>\n    <tr>\n      <th>1030</th>\n      <td>33</td>\n      <td>39</td>\n      <td>458.0</td>\n      <td>9.0</td>\n      <td>111.1</td>\n      <td>112.8</td>\n      <td>-1.58</td>\n      <td>2021</td>\n      <td>SAS</td>\n    </tr>\n    <tr>\n      <th>1031</th>\n      <td>31</td>\n      <td>41</td>\n      <td>431.0</td>\n      <td>11.0</td>\n      <td>114.6</td>\n      <td>114.9</td>\n      <td>-0.20</td>\n      <td>2021</td>\n      <td>NOP</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>17</td>\n      <td>55</td>\n      <td>236.0</td>\n      <td>25.0</td>\n      <td>108.8</td>\n      <td>116.7</td>\n      <td>-7.50</td>\n      <td>2021</td>\n      <td>HOU</td>\n    </tr>\n  </tbody>\n</table>\n<p>906 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_2b = cleaning_teamsdf_removeUnimportantRows(teams_2b)\n",
    "teams_2b = cleaning_teamsdf_convertStripToNan(teams_2b)\n",
    "teams_2b = cleaning_teamsdf_convertToAppropriateDatatype(teams_2b)\n",
    "teams_2b = cleaning_anyDf_removeStarInTeamName(teams_2b)\n",
    "teams_2b = cleaning_anyDf_convertTeamNamesToItsAbbrev(teams_2b, nicknames_df)\n",
    "teams_2b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def cleaning_inflationDf_separateDateColumns(us_inflation_2b, column='Yearmon', format=\"%d-%m-%Y\"):\n",
    "    us_inflation_2b = us_inflation_2b.copy()\n",
    "\n",
    "    dates = []\n",
    "    for i in range(len(us_inflation_2b)):\n",
    "        date = us_inflation_2b[column].iloc[i]\n",
    "        date = datetime.strptime(date, format)\n",
    "        dates.append(date)\n",
    "    us_inflation_2b['Year']  = [date.year for date in dates]\n",
    "    us_inflation_2b['Month'] = [date.month for date in dates]\n",
    "    us_inflation_2b['Day']   = [date.day for date in dates]\n",
    "\n",
    "    return us_inflation_2b\n",
    "\n",
    "\n",
    "def cleaning_inflationDf_getYearByMedian(us_inflation_2b):\n",
    "    \"\"\"\n",
    "    precondition: cleaning_inflationDf_separateDateColumns\n",
    "    \"\"\"\n",
    "    us_inflation_2b = us_inflation_2b.copy()\n",
    "    us_inflation_2b = cleaning_inflationDf_separateDateColumns(us_inflation_2b)\n",
    "    us_inflation_2b = us_inflation_2b.groupby(by='Year')['CPI'].median()\n",
    "    us_inflation_2b = us_inflation_2b.reset_index()\n",
    "    return us_inflation_2b\n",
    "\n",
    "\n",
    "def cleaning_anyDf_removeDuplicatedColumns(combined_df):\n",
    "    combined_df = combined_df.copy()\n",
    "    columns = combined_df.columns\n",
    "\n",
    "    columns_tobe_removed = []\n",
    "    for i in range(len(columns)):\n",
    "        col1 = columns[i]\n",
    "        for j in range(i+1, len(columns)):\n",
    "            col2 = columns[j]\n",
    "\n",
    "            if (combined_df[col1] == combined_df[col2]).all():\n",
    "                columns_tobe_removed.append(col1)\n",
    "    columns_tobe_kept = set(combined_df.columns) - set(columns_tobe_removed)\n",
    "    columns_tobe_kept = list(columns_tobe_kept)\n",
    "    return combined_df.loc[:, columns_tobe_kept]\n",
    "\n",
    "def cleaning_anyDf_recalculateWLpercentage(teams_2b):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b['W/L%'] = 100*teams_2b.W / (teams_2b.W + teams_2b.L)\n",
    "    return teams_2b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "data": {
      "text/plain": "      Yearmon  CPI\n0  01-01-1913  9.8\n1  01-02-1913  9.8\n2  01-03-1913  9.8\n3  01-04-1913  9.8\n4  01-05-1913  9.7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Yearmon</th>\n      <th>CPI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01-01-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01-02-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01-03-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01-04-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01-05-1913</td>\n      <td>9.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_inflation_2b.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "data": {
      "text/plain": "     Year       CPI\n0    1913    9.8500\n1    1914   10.0000\n2    1915   10.1000\n3    1916   10.8000\n4    1917   12.9000\n..    ...       ...\n104  2017  244.8705\n105  2018  251.7885\n106  2019  256.3505\n107  2020  258.8895\n108  2021  267.0540\n\n[109 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>CPI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1913</td>\n      <td>9.8500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1914</td>\n      <td>10.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1915</td>\n      <td>10.1000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1916</td>\n      <td>10.8000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1917</td>\n      <td>12.9000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>2017</td>\n      <td>244.8705</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>2018</td>\n      <td>251.7885</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>2019</td>\n      <td>256.3505</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>2020</td>\n      <td>258.8895</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>2021</td>\n      <td>267.0540</td>\n    </tr>\n  </tbody>\n</table>\n<p>109 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_inflationDf_getYearByMedian(cleaning_inflationDf_separateDateColumns(us_inflation_2b))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pada kasus ini kami memutuskan mengambil median dari inflasi karena CPI merupakan perbandingan inflasi pada tahun ini dengan inflasi pada suatu tahun yang dijadikan pivot. Karena CPI merupakan suatu perbandingan, maka kami merasa bahwa mengambil median lebih tepat dibandingkan mengambil mean-nya."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "us_inflation_2b_cleaned = us_inflation_2b.copy()\n",
    "us_inflation_2b_cleaned = cleaning_inflationDf_separateDateColumns(us_inflation_2b_cleaned)\n",
    "us_inflation_2b_cleaned = cleaning_inflationDf_getYearByMedian(us_inflation_2b_cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "data": {
      "text/plain": "   Year    CPI   W   L       W/L%    GB   PS/G   PA/G   SRS Team\n0  1991  136.1  56  26  68.292683   NaN  111.5  105.7  5.22  BOS\n1  1991  136.1  44  38  53.658537  12.0  105.4  105.6 -0.39  PHI\n2  1991  136.1  39  43  47.560976  17.0  103.1  103.3 -0.43  NYK",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>CPI</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n      <th>Team</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>56</td>\n      <td>26</td>\n      <td>68.292683</td>\n      <td>NaN</td>\n      <td>111.5</td>\n      <td>105.7</td>\n      <td>5.22</td>\n      <td>BOS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>44</td>\n      <td>38</td>\n      <td>53.658537</td>\n      <td>12.0</td>\n      <td>105.4</td>\n      <td>105.6</td>\n      <td>-0.39</td>\n      <td>PHI</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>39</td>\n      <td>43</td>\n      <td>47.560976</td>\n      <td>17.0</td>\n      <td>103.1</td>\n      <td>103.3</td>\n      <td>-0.43</td>\n      <td>NYK</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = us_inflation_2b_cleaned.merge(teams_2b, left_on=[\"Year\"], right_on=[\"Year\"])\n",
    "combined_df = cleaning_anyDf_recalculateWLpercentage(combined_df)\n",
    "combined_df.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "mvp_stats_2b = mvp_stats_2b.drop('Tm', axis=1)  # karena sudah ada kolom Team\n",
    "mvp_stats_2b = cleaning_anyDf_convertTeamNamesToItsAbbrev(mvp_stats_2b, nicknames_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "data": {
      "text/plain": "        Player Pos  Age   G  GS    MP   FG   FGA    FG%   3P  ...  Pts Max  \\\n0   A.C. Green  PF   27  82  21  26.4  3.1   6.6  476.0  0.1  ...        0   \n1  Byron Scott  SG   29  82  82  32.1  6.1  12.8  477.0  0.9  ...        0   \n\n   Share  Team   W   L   W/L%   GB   PS/G  PA/G   SRS  \n0    0.0   LAL  58  24  707.0  5.0  106.3  99.6  6.73  \n1    0.0   LAL  58  24  707.0  5.0  106.3  99.6  6.73  \n\n[2 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Player</th>\n      <th>Pos</th>\n      <th>Age</th>\n      <th>G</th>\n      <th>GS</th>\n      <th>MP</th>\n      <th>FG</th>\n      <th>FGA</th>\n      <th>FG%</th>\n      <th>3P</th>\n      <th>...</th>\n      <th>Pts Max</th>\n      <th>Share</th>\n      <th>Team</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A.C. Green</td>\n      <td>PF</td>\n      <td>27</td>\n      <td>82</td>\n      <td>21</td>\n      <td>26.4</td>\n      <td>3.1</td>\n      <td>6.6</td>\n      <td>476.0</td>\n      <td>0.1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>LAL</td>\n      <td>58</td>\n      <td>24</td>\n      <td>707.0</td>\n      <td>5.0</td>\n      <td>106.3</td>\n      <td>99.6</td>\n      <td>6.73</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Byron Scott</td>\n      <td>SG</td>\n      <td>29</td>\n      <td>82</td>\n      <td>82</td>\n      <td>32.1</td>\n      <td>6.1</td>\n      <td>12.8</td>\n      <td>477.0</td>\n      <td>0.9</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>LAL</td>\n      <td>58</td>\n      <td>24</td>\n      <td>707.0</td>\n      <td>5.0</td>\n      <td>106.3</td>\n      <td>99.6</td>\n      <td>6.73</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 40 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   Year    CPI   W   L       W/L%    GB   PS/G   PA/G   SRS Team\n0  1991  136.1  56  26  68.292683   NaN  111.5  105.7  5.22  BOS\n1  1991  136.1  44  38  53.658537  12.0  105.4  105.6 -0.39  PHI",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>CPI</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n      <th>Team</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>56</td>\n      <td>26</td>\n      <td>68.292683</td>\n      <td>NaN</td>\n      <td>111.5</td>\n      <td>105.7</td>\n      <td>5.22</td>\n      <td>BOS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>44</td>\n      <td>38</td>\n      <td>53.658537</td>\n      <td>12.0</td>\n      <td>105.4</td>\n      <td>105.6</td>\n      <td>-0.39</td>\n      <td>PHI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyaknya null salaries:  28074\n",
      "banyaknya null player name salaries:  0\n",
      "banyaknya null player name mvp stats:  0\n",
      "banyaknya null team name:  0\n",
      "\n",
      "banyaknya row salaries df :  37420\n",
      "banyaknya row mvp statsdf :  14092\n",
      "banyaknya row combined df :  906\n"
     ]
    }
   ],
   "source": [
    "display(mvp_stats_2b.head(2))\n",
    "display(combined_df.head(2))\n",
    "print('banyaknya null salaries: ', salaries_2b.Salaries.isna().sum())\n",
    "print('banyaknya null player name salaries: ', salaries_2b.Name.isna().sum())\n",
    "print('banyaknya null player name mvp stats: ', mvp_stats_2b.Player.isna().sum())\n",
    "print('banyaknya null team name: ', combined_df.Team.isna().sum())\n",
    "print()\n",
    "print('banyaknya row salaries df : ', len(salaries_2b))\n",
    "print('banyaknya row mvp statsdf : ', len(mvp_stats_2b))\n",
    "print('banyaknya row combined df : ', len(combined_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "data": {
      "text/plain": "    TRB  TOV  GS  SRS_y  Year  Pts Max   FTA     W/L%_y  GB_y  \\\n0  13.6  2.8  79   8.41  2000     1210  10.4  81.707317   NaN   \n1  11.8  3.3  81   2.67  2000     1210   5.0  60.975610   5.0   \n2   9.5  2.7  78   2.75  2000     1210   7.4  63.414634   NaN   \n3   5.7  2.7  82  -3.47  2000        0   3.4  35.365854  23.0   \n4   6.3  2.5  82   6.36  2000        0   2.7  71.951220   8.0   \n\n             Player  ...   2PA  GB_x    2P    CPI  Team  Rank    FG%  STL   G  \\\n0  Shaquille O'Neal  ...  21.1   0.0  12.1  172.6   LAL     1  574.0  0.5  79   \n1     Kevin Garnett  ...  17.8   5.0   9.0  172.6   MIN     2  497.0  1.5  81   \n2   Alonzo Mourning  ...  14.9   0.0   8.3  172.6   MIA     3  551.0  0.5  79   \n3      Juwan Howard  ...  13.4  23.0   6.2  172.6   WAS     4  459.0  0.8  82   \n4    Scottie Pippen  ...   7.3   8.0   3.7  172.6   POR     5  451.0  1.4  82   \n\n    eFG%  \n0  574.0  \n1  507.0  \n2  551.0  \n3  459.0  \n4  501.0  \n\n[5 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TRB</th>\n      <th>TOV</th>\n      <th>GS</th>\n      <th>SRS_y</th>\n      <th>Year</th>\n      <th>Pts Max</th>\n      <th>FTA</th>\n      <th>W/L%_y</th>\n      <th>GB_y</th>\n      <th>Player</th>\n      <th>...</th>\n      <th>2PA</th>\n      <th>GB_x</th>\n      <th>2P</th>\n      <th>CPI</th>\n      <th>Team</th>\n      <th>Rank</th>\n      <th>FG%</th>\n      <th>STL</th>\n      <th>G</th>\n      <th>eFG%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.6</td>\n      <td>2.8</td>\n      <td>79</td>\n      <td>8.41</td>\n      <td>2000</td>\n      <td>1210</td>\n      <td>10.4</td>\n      <td>81.707317</td>\n      <td>NaN</td>\n      <td>Shaquille O'Neal</td>\n      <td>...</td>\n      <td>21.1</td>\n      <td>0.0</td>\n      <td>12.1</td>\n      <td>172.6</td>\n      <td>LAL</td>\n      <td>1</td>\n      <td>574.0</td>\n      <td>0.5</td>\n      <td>79</td>\n      <td>574.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11.8</td>\n      <td>3.3</td>\n      <td>81</td>\n      <td>2.67</td>\n      <td>2000</td>\n      <td>1210</td>\n      <td>5.0</td>\n      <td>60.975610</td>\n      <td>5.0</td>\n      <td>Kevin Garnett</td>\n      <td>...</td>\n      <td>17.8</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>172.6</td>\n      <td>MIN</td>\n      <td>2</td>\n      <td>497.0</td>\n      <td>1.5</td>\n      <td>81</td>\n      <td>507.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.5</td>\n      <td>2.7</td>\n      <td>78</td>\n      <td>2.75</td>\n      <td>2000</td>\n      <td>1210</td>\n      <td>7.4</td>\n      <td>63.414634</td>\n      <td>NaN</td>\n      <td>Alonzo Mourning</td>\n      <td>...</td>\n      <td>14.9</td>\n      <td>0.0</td>\n      <td>8.3</td>\n      <td>172.6</td>\n      <td>MIA</td>\n      <td>3</td>\n      <td>551.0</td>\n      <td>0.5</td>\n      <td>79</td>\n      <td>551.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.7</td>\n      <td>2.7</td>\n      <td>82</td>\n      <td>-3.47</td>\n      <td>2000</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>35.365854</td>\n      <td>23.0</td>\n      <td>Juwan Howard</td>\n      <td>...</td>\n      <td>13.4</td>\n      <td>23.0</td>\n      <td>6.2</td>\n      <td>172.6</td>\n      <td>WAS</td>\n      <td>4</td>\n      <td>459.0</td>\n      <td>0.8</td>\n      <td>82</td>\n      <td>459.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>82</td>\n      <td>6.36</td>\n      <td>2000</td>\n      <td>0</td>\n      <td>2.7</td>\n      <td>71.951220</td>\n      <td>8.0</td>\n      <td>Scottie Pippen</td>\n      <td>...</td>\n      <td>7.3</td>\n      <td>8.0</td>\n      <td>3.7</td>\n      <td>172.6</td>\n      <td>POR</td>\n      <td>5</td>\n      <td>451.0</td>\n      <td>1.4</td>\n      <td>82</td>\n      <td>501.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 45 columns</p>\n</div>"
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_2b = salaries_2b[[\"Name\", \"Year\", \"Salaries\", \"Rank\"]]\n",
    "\n",
    "combined_df = mvp_stats_2b.merge(combined_df, left_on=[\"Team\", \"Year\"], right_on=[\"Team\", \"Year\"])\n",
    "combined_df = salaries_2b.merge(combined_df, left_on=[\"Name\", \"Year\"], right_on=[\"Player\", \"Year\"])\n",
    "combined_df = cleaning_anyDf_removeDuplicatedColumns(combined_df)\n",
    "\n",
    "combined_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya data duplikat:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Banyaknya data duplikat: \", combined_df.duplicated().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8323 entries, 0 to 8322\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   TRB       8323 non-null   float64\n",
      " 1   TOV       8323 non-null   float64\n",
      " 2   GS        8323 non-null   int64  \n",
      " 3   SRS_y     8323 non-null   float64\n",
      " 4   Year      8323 non-null   int64  \n",
      " 5   Pts Max   8323 non-null   int64  \n",
      " 6   FTA       8323 non-null   float64\n",
      " 7   W/L%_y    8323 non-null   float64\n",
      " 8   GB_y      6705 non-null   float64\n",
      " 9   Player    8323 non-null   object \n",
      " 10  Pos       8323 non-null   object \n",
      " 11  W_y       8323 non-null   int64  \n",
      " 12  3P%       7118 non-null   float64\n",
      " 13  PF        8323 non-null   float64\n",
      " 14  3PA       8323 non-null   float64\n",
      " 15  Salaries  7933 non-null   float64\n",
      " 16  Age       8323 non-null   int64  \n",
      " 17  FGA       8323 non-null   float64\n",
      " 18  PS/G_y    8323 non-null   float64\n",
      " 19  MP        8323 non-null   float64\n",
      " 20  FT        8323 non-null   float64\n",
      " 21  FG        8323 non-null   float64\n",
      " 22  DRB       8323 non-null   float64\n",
      " 23  W/L%_x    8323 non-null   float64\n",
      " 24  AST       8323 non-null   float64\n",
      " 25  3P        8323 non-null   float64\n",
      " 26  2P%       8276 non-null   float64\n",
      " 27  PTS       8323 non-null   float64\n",
      " 28  L_y       8323 non-null   int64  \n",
      " 29  PA/G_y    8323 non-null   float64\n",
      " 30  ORB       8323 non-null   float64\n",
      " 31  Pts Won   8323 non-null   int64  \n",
      " 32  BLK       8323 non-null   float64\n",
      " 33  Share     8323 non-null   float64\n",
      " 34  FT%       8066 non-null   float64\n",
      " 35  2PA       8323 non-null   float64\n",
      " 36  GB_x      8323 non-null   float64\n",
      " 37  2P        8323 non-null   float64\n",
      " 38  CPI       8323 non-null   float64\n",
      " 39  Team      8323 non-null   object \n",
      " 40  Rank      8323 non-null   int64  \n",
      " 41  FG%       8296 non-null   float64\n",
      " 42  STL       8323 non-null   float64\n",
      " 43  G         8323 non-null   int64  \n",
      " 44  eFG%      8296 non-null   float64\n",
      "dtypes: float64(33), int64(9), object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Drop missing values pada target feature\n",
    "\n",
    "kami memutuskan untuk mendrop missing values pada target feature karena target feature merupakan ground truth. Oleh karena itu, kami tidak setuju apabila kita melakukan imputasi untuk missing values pada kolom ini. Sebab, apabila kita melakukan imputasi terhadap missing values untuk kolom ini, maka kolom ini tidak sepenuhnya menjadi ground truth lagi karena diisikan dengan data-data sintesis yang tidak diketahui kebenarannya."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyak missing values pada kolom Salaries:  390\n"
     ]
    },
    {
     "data": {
      "text/plain": "TRB            0\nTOV            0\nGS             0\nSRS_y          0\nYear           0\nPts Max        0\nFTA            0\nW/L%_y         0\nGB_y        1571\nPlayer         0\nPos            0\nW_y            0\n3P%         1117\nPF             0\n3PA            0\nSalaries       0\nAge            0\nFGA            0\nPS/G_y         0\nMP             0\nFT             0\nFG             0\nDRB            0\nW/L%_x         0\nAST            0\n3P             0\n2P%           43\nPTS            0\nL_y            0\nPA/G_y         0\nORB            0\nPts Won        0\nBLK            0\nShare          0\nFT%          230\n2PA            0\nGB_x           0\n2P             0\nCPI            0\nTeam           0\nRank           0\nFG%           25\nSTL            0\nG              0\neFG%          25\ndtype: int64"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Banyak missing values pada kolom Salaries: \", combined_df.Salaries.isna().sum())\n",
    "combined_df = combined_df[combined_df.Salaries.notna()]\n",
    "combined_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Memisahkan kolom-kolom menjadi feature (X) dan target (y) dan drop fitur-fitur yang tidak diperlukan\n",
    "\n",
    "Pada dataset ini, kita sudah memiliki gabungan seluruh feature mengenai statistik performa team dan statistik performa pemain. Oleh karena itu, nama tim dan nama pemain sudah tidak lagi berkaitan dengan gaji yang diperoleh. Nama tim sudah dapat digantikan dengan data mengenai performa tim, dan nama pemain dapat digantikan dengan data mengenai performa pemain.\n",
    "\n",
    "Sementara itu, kita melakukan drop kolom Rank karena kolom tersebut merupakan Ranking gaji seorang pemain pada tahun itu. Oleh karena itu, kami merasa informasi ini tidak valid untuk dijadikan dasar dalam memprediksi gaji pemain."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "data": {
      "text/plain": "    TRB  TOV  GS  SRS_y  Year  Pts Max   FTA     W/L%_y  GB_y Pos  ...  Share  \\\n0  13.6  2.8  79   8.41  2000     1210  10.4  81.707317   NaN   C  ...  998.0   \n1  11.8  3.3  81   2.67  2000     1210   5.0  60.975610   5.0  PF  ...  337.0   \n\n     FT%   2PA  GB_x    2P    CPI    FG%  STL   G   eFG%  \n0  524.0  21.1   0.0  12.1  172.6  574.0  0.5  79  574.0  \n1  765.0  17.8   5.0   9.0  172.6  497.0  1.5  81  507.0  \n\n[2 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TRB</th>\n      <th>TOV</th>\n      <th>GS</th>\n      <th>SRS_y</th>\n      <th>Year</th>\n      <th>Pts Max</th>\n      <th>FTA</th>\n      <th>W/L%_y</th>\n      <th>GB_y</th>\n      <th>Pos</th>\n      <th>...</th>\n      <th>Share</th>\n      <th>FT%</th>\n      <th>2PA</th>\n      <th>GB_x</th>\n      <th>2P</th>\n      <th>CPI</th>\n      <th>FG%</th>\n      <th>STL</th>\n      <th>G</th>\n      <th>eFG%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.6</td>\n      <td>2.8</td>\n      <td>79</td>\n      <td>8.41</td>\n      <td>2000</td>\n      <td>1210</td>\n      <td>10.4</td>\n      <td>81.707317</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>...</td>\n      <td>998.0</td>\n      <td>524.0</td>\n      <td>21.1</td>\n      <td>0.0</td>\n      <td>12.1</td>\n      <td>172.6</td>\n      <td>574.0</td>\n      <td>0.5</td>\n      <td>79</td>\n      <td>574.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11.8</td>\n      <td>3.3</td>\n      <td>81</td>\n      <td>2.67</td>\n      <td>2000</td>\n      <td>1210</td>\n      <td>5.0</td>\n      <td>60.975610</td>\n      <td>5.0</td>\n      <td>PF</td>\n      <td>...</td>\n      <td>337.0</td>\n      <td>765.0</td>\n      <td>17.8</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>172.6</td>\n      <td>497.0</td>\n      <td>1.5</td>\n      <td>81</td>\n      <td>507.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 41 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     Salaries\n0  17142000.0\n1  16806000.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Salaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17142000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16806000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_2b, y_2b = combined_df.drop(\"Salaries\", axis=1), combined_df[[\"Salaries\"]]\n",
    "x_2b.drop(\"Team\", axis=1, inplace=True)\n",
    "x_2b.drop(\"Player\", axis=1, inplace=True)\n",
    "x_2b.drop(\"Rank\", axis=1, inplace=True)\n",
    "\n",
    "display(x_2b.head(2))\n",
    "display(y_2b.head(2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Membagi dataset menjadi training, testing, dan final testing\n",
    "\n",
    "Kami memutuskan untuk membagi dataset menjadi training, testing, dan final testing. Dataset final testing diperlukan karena kita sangat disarankan untuk memasuki fase testing hanya sekali saja, yakni ketika kita sudah benar-benar yakin dengan model yang kita bangun dan sudah tidak ingin mengutak-atik modelnya lagi. Oleh karena itu, kami memutuskan untuk membagi dataset testing menjadi testing untuk mengecek performa, dan final testing untuk model yang sudah final."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    "x_2b_train, x2b_final_test, y_2b_train, y_2b_final_test = train_test_split(\n",
    "    x_2b, y_2b, test_size=0.2, random_state=random_state\n",
    ")\n",
    "del x_2b\n",
    "del y_2b\n",
    "\n",
    "x_2b_train, x2b_test, y_2b_train, y_2b_test = train_test_split(\n",
    "    x_2b_train, y_2b_train, test_size=0.2, random_state=random_state,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B Pipeline Design, Training model, dan Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pada bagian ini, kita akan merancang pipeline mengenai alur pemrosesan data. Pipeline ini memiliki 5 tahapan: *encode* data kategorikal, menerapkan *scaling* & *standarisasi*, mengisi *missing values*, menerapkan *feature selection* , dan melakukan *training*/prediksi.\n",
    "\n",
    "Beberapa tahapan dapat memiliki beberapa alternatif yang ingin dicoba. Misalnya, pada tahapan standarisasi kami mencoba metode MinMaxScaler, StandardScaler, dan RobustScaler. Setelah itu kami akan memilih metode yang menghasilkan akurasi terbaik. Oleh karena itu, kami akan memanfaatkan `GridSearchCV` untuk mencoba semua kombinasi tersebut."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "def cartesian_product_of_dict_lists(*multiple_list_of_dicts):\n",
    "    if len(multiple_list_of_dicts) == 0:\n",
    "        return []\n",
    "\n",
    "    if len(multiple_list_of_dicts) == 1:\n",
    "        return multiple_list_of_dicts[0]\n",
    "\n",
    "    if len(multiple_list_of_dicts) == 2:\n",
    "        ret = []\n",
    "        for dict1 in multiple_list_of_dicts[0]:\n",
    "            for dict2 in multiple_list_of_dicts[1]:\n",
    "                ret.append(dict(**dict1, **dict2))\n",
    "        return ret\n",
    "\n",
    "    curr = [{}]\n",
    "    for dct in multiple_list_of_dicts:\n",
    "        curr = cartesian_product_of_dict_lists(curr, dct)\n",
    "    return curr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin #gives fit_transform method for free\n",
    "\n",
    "# LabelEncoder tidak dapat dimasukkan ke dalam pipeline karena\n",
    "# LabelEncoder.transform() hanya memiliki 1 parameter, sedangkan pipeline akan memberikan 2 parameter\n",
    "\n",
    "class MyLabelEncoder(TransformerMixin):\n",
    "    # source: https://stackoverflow.com/a/46619402/7069108\n",
    "    def __init__(self, columns_to_be_encoded:dict[str, list[str]],\n",
    "                 *args, **kwargs):\n",
    "        \"\"\"\n",
    "        :param columns_to_be_encoded: dictionary, di mana keys-nya menyatakan kolom-kolom apa saja yang ingin di-encode, dan values-nya menyatakan list daftar semua nilai-nilai pada kelas kategorikal tersebut. None jika kita ingin mengambil berdasarkan fit yang diberikan pada MyLabelEncoder ini\n",
    "\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "        self.encoders = {\n",
    "            column: preprocessing.LabelEncoder(*args, **kwargs)\n",
    "                for column in columns_to_be_encoded.keys()\n",
    "        }\n",
    "        self.possible_values = columns_to_be_encoded\n",
    "        for col, possible_values in columns_to_be_encoded.items():\n",
    "            if possible_values is None:\n",
    "                continue\n",
    "            self.encoders[col].fit(possible_values)\n",
    "\n",
    "    def fit(self, x, y=0):\n",
    "        for col, encoder in self.encoders.items():\n",
    "            possible_values = self.possible_values[col]\n",
    "            if possible_values is None:\n",
    "                encoder.fit(x[col])\n",
    "                continue\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=0):\n",
    "        x = x.copy()\n",
    "        for col, encoder in self.encoders.items():\n",
    "            x[col] = encoder.transform(x[col])\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "label_encoder_params = [{\n",
    "    'encoding': [\n",
    "        MyLabelEncoder({\n",
    "            \"Pos\": ['C', 'PF', 'SF', 'PG', 'SG', 'SF-SG', 'C-PF', 'PG-SG', 'SF-PF',\n",
    "                    'PG-SF', 'PF-C', 'SG-SF', 'SG-PG', 'PF-SF', 'SG-PF']\n",
    "        })\n",
    "    ]\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "scaler1 = preprocessing.MinMaxScaler()\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "scaler3 = preprocessing.RobustScaler()\n",
    "\n",
    "scaler_params = [{\n",
    "    'scaler': [None, scaler3, scaler2, scaler1],\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "imputer1 = SimpleImputer()\n",
    "imputer2 = KNNImputer()\n",
    "\n",
    "imputer_params = [{\n",
    "    'imputer': [imputer2, imputer1],\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "feature_selector1 = SelectFromModel(estimator=Lasso())\n",
    "feature_selector2 = SelectKBest()\n",
    "\n",
    "feature_selector_params = [{\n",
    "    'feature_selector': [feature_selector1],\n",
    "    'feature_selector__estimator__alpha': [0.2, 0.1, 0.01]\n",
    "}, {\n",
    "    'feature_selector': [feature_selector2],\n",
    "    'feature_selector__k': [7, 8, 9],\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kami sudah mencoba GridSearcCV untuk membandingkan model KNeighborsRegressor, LinearRegression, MLPRegressor (relu & tanh), dan RandomForestRegressor. Hasilnya, urutan model mulai dari yang terbaik hingga yang terburuk adalah RandomForestRegressor, LiinearRegression, KNeighborsRegressor, dan MLPRegressor. Supaya *running time* lebih efisien, kami memutuskan untuk memasukkan model RandomForestRegressor saja, dan mengabaikan model lainnya yang tidak sebagus RandomForestRegressor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "predictor_params = [\n",
    "    {\n",
    "        'predictor': [\n",
    "            RandomForestRegressor(),\n",
    "        ],\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('encoding', None),\n",
    "        ('scaler', None),\n",
    "        ('imputer', None),\n",
    "        ('feature_selector', None),\n",
    "        ('predictor', None),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [],
   "source": [
    "grid_params = cartesian_product_of_dict_lists(\n",
    "    label_encoder_params,\n",
    "    scaler_params,\n",
    "    imputer_params,\n",
    "    feature_selector_params,\n",
    "    predictor_params\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'encoding': [<__main__.MyLabelEncoder at 0x1f40620ba30>],\n  'scaler': [None, RobustScaler(), StandardScaler(), MinMaxScaler()],\n  'imputer': [KNNImputer(), SimpleImputer()],\n  'feature_selector': [SelectFromModel(estimator=Lasso())],\n  'feature_selector__estimator__alpha': [0.2, 0.1, 0.01],\n  'predictor': [RandomForestRegressor()]},\n {'encoding': [<__main__.MyLabelEncoder at 0x1f40620ba30>],\n  'scaler': [None, RobustScaler(), StandardScaler(), MinMaxScaler()],\n  'imputer': [KNNImputer(), SimpleImputer()],\n  'feature_selector': [SelectKBest()],\n  'feature_selector__k': [7, 8, 9],\n  'predictor': [RandomForestRegressor()]}]"
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [
    "def perform_grid_search_cv():\n",
    "    grid_search_cv = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=grid_params,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=10,\n",
    "        error_score='raise',\n",
    "    )\n",
    "\n",
    "    grid_search_cv.fit(x_2b_train, y_2b_train.Salaries)\n",
    "    return grid_search_cv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\01 Kuliah\\01 Dokumen\\52 - KASDD\\proyek-akhir\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.140e+16, tolerance: 1.397e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "file_name = \"grid_search_cv_2b.pkl\"\n",
    "try:\n",
    "    grid_search_cv = joblib.load(file_name)\n",
    "except FileNotFoundError:\n",
    "    grid_search_cv = perform_grid_search_cv()\n",
    "    joblib.dump(grid_search_cv, file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  -10285990169767.484\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -10307137539701.35\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -10316370569556.137\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -10321626520616.732\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -10323301298115.883\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -10329813520854.986\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -10337093718226.305\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -10343140733457.676\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -10350637918454.363\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -10364331098982.105\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -10367056591208.064\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -10367442183523.246\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -10367838772724.043\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -10368746524802.352\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -10372165375673.914\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -10381290090990.484\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -10387900298966.875\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -10398507792822.88\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -10401385528575.244\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -10404841126169.332\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.2, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -10412061749400.08\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -10414168214258.213\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.1, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -10422355692541.234\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -10439799926103.3\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)), 'feature_selector__estimator__alpha': 0.01, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -17103079634538.105\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -17120867709572.818\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -17130299318796.531\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -17164095374331.426\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -17171844462601.662\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -17194669641838.098\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -17201366432272.824\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -17207805934787.098\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 9, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -17270904990436.787\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -17327919473401.021\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -17336050801234.062\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -17345586839478.072\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -17386619531518.979\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -17434137505150.887\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -17454035569644.088\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -17460549916008.625\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 8, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -17515758194823.496\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -17525652029372.322\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n",
      "Score:  -17529042994138.895\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': RobustScaler()}\n",
      "\n",
      "Score:  -17562228428410.16\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -17573055622538.848\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': MinMaxScaler()}\n",
      "\n",
      "Score:  -17599083902886.098\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': KNNImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -17642206108608.777\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': None}\n",
      "\n",
      "Score:  -17652866693404.207\n",
      "{'encoding': <__main__.MyLabelEncoder object at 0x000001F40620BA30>, 'feature_selector': SelectKBest(), 'feature_selector__k': 7, 'imputer': SimpleImputer(), 'predictor': RandomForestRegressor(), 'scaler': StandardScaler()}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the scores for all hyperparameter combinations\n",
    "cv_results = grid_search_cv.cv_results_\n",
    "scores = []\n",
    "for params_combination in cv_results['params']:\n",
    "    score = cv_results['mean_test_score'][cv_results['params'].index(params_combination)]\n",
    "    scores.append((score, params_combination))\n",
    "\n",
    "# sort berdasarkan score terbesar (berdasarkan error yang terkecil)\n",
    "scores.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "# Print the scores for each combination\n",
    "for score, params_combination in scores:\n",
    "    print(\"Score: \", score)\n",
    "    print(f\"{params_combination}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:  0.6181330675779773\n",
      "Rata-rata error absolut:  2134073.7031889767\n",
      "Rata-rata error relatif:  0.4632846204294282\n"
     ]
    }
   ],
   "source": [
    "best_pipeline = grid_search_cv.best_estimator_\n",
    "\n",
    "y_2b_predict = best_pipeline.predict(x2b_test)\n",
    "mae = metrics.mean_absolute_error(y_2b_test, y_2b_predict)\n",
    "r2 = metrics.r2_score(y_2b_test, y_2b_predict)\n",
    "\n",
    "print(\"R2 score: \", r2)\n",
    "print(\"Rata-rata error absolut: \", mae)\n",
    "print(\"Rata-rata error relatif: \", mae / y_2b_test.Salaries.mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('encoding',\n                 <__main__.MyLabelEncoder object at 0x000001F406266170>),\n                ('scaler', None), ('imputer', SimpleImputer()),\n                ('feature_selector',\n                 SelectFromModel(estimator=Lasso(alpha=0.01))),\n                ('predictor', RandomForestRegressor())])",
      "text/html": "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;encoding&#x27;,\n                 &lt;__main__.MyLabelEncoder object at 0x000001F406266170&gt;),\n                (&#x27;scaler&#x27;, None), (&#x27;imputer&#x27;, SimpleImputer()),\n                (&#x27;feature_selector&#x27;,\n                 SelectFromModel(estimator=Lasso(alpha=0.01))),\n                (&#x27;predictor&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;encoding&#x27;,\n                 &lt;__main__.MyLabelEncoder object at 0x000001F406266170&gt;),\n                (&#x27;scaler&#x27;, None), (&#x27;imputer&#x27;, SimpleImputer()),\n                (&#x27;feature_selector&#x27;,\n                 SelectFromModel(estimator=Lasso(alpha=0.01))),\n                (&#x27;predictor&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MyLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.MyLabelEncoder object at 0x000001F406266170&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feature_selector: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=Lasso(alpha=0.01))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.01)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.01)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "data": {
      "text/plain": "{'encoding': <__main__.MyLabelEncoder at 0x1f40620ba30>,\n 'feature_selector': SelectFromModel(estimator=Lasso(alpha=0.01)),\n 'feature_selector__estimator__alpha': 0.01,\n 'imputer': SimpleImputer(),\n 'predictor': RandomForestRegressor(),\n 'scaler': None}"
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur-fitur terbaik: \n",
      "\n",
      "TRB, TOV, GS, SRS_y, Year, Pts Max, FTA, W/L%_y, GB_y, Pos, W_y, 3P%, PF, 3PA, Age, FGA, PS/G_y, MP, FT, FG, DRB, W/L%_x, AST, 3P, 2P%, PTS, L_y, PA/G_y, ORB, Pts Won, BLK, Share, FT%, 2PA, GB_x, 2P, CPI, FG%, STL, G, eFG%\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitur-fitur terbaik: \")\n",
    "print()\n",
    "print(\", \".join(\n",
    "        best_pipeline['feature_selector'].get_feature_names_out(input_features=x_2b_train.columns)\n",
    "))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
