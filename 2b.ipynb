{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.preprocessing as preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "random_state = 42"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas._libs.parsers import k\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_10876\\3205523321.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  mvp_stats_2b = pd.read_csv(\"datasets/player_mvp_stats.csv\", ';')\n",
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_10876\\3205523321.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  nicknames_df = pd.read_csv(\"datasets/nicknames.csv\", ';')\n",
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_10876\\3205523321.py:4: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  teams_2b = pd.read_csv(\"datasets/teams.csv\", ';')\n"
     ]
    }
   ],
   "source": [
    "mvp_stats_2b = pd.read_csv(\"datasets/player_mvp_stats.csv\", ';')\n",
    "nicknames_df = pd.read_csv(\"datasets/nicknames.csv\", ';')\n",
    "salaries_2b = pd.read_csv(\"datasets/salaries.csv\")\n",
    "teams_2b = pd.read_csv(\"datasets/teams.csv\", ';')\n",
    "us_inflation_2b = pd.read_csv(\"datasets/US CPI.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Preprocess dan merge beberapa dataset menjadi satu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def dataframe_to_dict(nicknames_df, key_column_name='Name', value_column_name='Abbreviation'):\n",
    "    keys = nicknames_df[key_column_name]\n",
    "    values = nicknames_df[value_column_name]\n",
    "    return dict(zip(keys, values))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def cleaning_teamsdf_removeUnimportantRows(teams_2b):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    important_rows = ~teams_2b.W.str.contains(\"Division\")\n",
    "    return teams_2b[important_rows]\n",
    "\n",
    "def cleaning_teamsdf_convertStripToNan(teams_2b):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b.GB = teams_2b.GB.replace(\"â€”\", np.NAN)\n",
    "    return teams_2b\n",
    "\n",
    "def cleaning_teamsdf_convertToAppropriateDatatype(teams_2b):\n",
    "    \"\"\"\n",
    "    preconditions:\n",
    "        cleaning_teamsdf_removeUnimportantRows\n",
    "         cleaning_teamsdf_convertStripToNan\n",
    "    \"\"\"\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b.W = pd.to_numeric(teams_2b.W)\n",
    "    teams_2b.L = pd.to_numeric(teams_2b.L)\n",
    "    teams_2b['W/L%'] = pd.to_numeric(teams_2b['W/L%'])\n",
    "    teams_2b.GB = pd.to_numeric(teams_2b.GB)\n",
    "    teams_2b['PS/G'] = pd.to_numeric(teams_2b['PS/G'])\n",
    "    teams_2b['PA/G'] = pd.to_numeric(teams_2b['PA/G'])\n",
    "    teams_2b.SRS = pd.to_numeric(teams_2b.SRS)\n",
    "    return teams_2b\n",
    "\n",
    "def cleaning_anyDf_removeStarInTeamName(teams_2b, column_name='Team'):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b[column_name] = teams_2b[column_name].str.replace('*', '')\n",
    "    return teams_2b\n",
    "\n",
    "\n",
    "def cleaning_anyDf_convertTeamNamesToItsAbbrev(teams_2b, nicknames_df, column_name='Team'):\n",
    "    \"\"\"\n",
    "    precondition:\n",
    "        teams df:\n",
    "            cleaning_anyDf_removeStarInTeamName\n",
    "    \"\"\"\n",
    "    nicknames_df = nicknames_df.copy()\n",
    "    teams_2b = teams_2b.copy()\n",
    "\n",
    "    nicknames_df = nicknames_df.drop_duplicates(subset='Name', keep='first')\n",
    "    mapping = dataframe_to_dict(nicknames_df)\n",
    "    mapping |= dataframe_to_dict(nicknames_df, 'Abbreviation', 'Abbreviation')\n",
    "\n",
    "    teams_2b[column_name] = list(map(\n",
    "        lambda x: mapping[x],\n",
    "        teams_2b[column_name]\n",
    "    ))\n",
    "    return teams_2b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imman\\AppData\\Local\\Temp\\ipykernel_10876\\1280597476.py:29: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  teams_2b[column_name] = teams_2b[column_name].str.replace('*', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": "       W   L   W/L%    GB   PS/G   PA/G   SRS  Year Team\n0     56  26  683.0   NaN  111.5  105.7  5.22  1991  BOS\n1     44  38  537.0  12.0  105.4  105.6 -0.39  1991  PHI\n2     39  43  476.0  17.0  103.1  103.3 -0.43  1991  NYK\n3     30  52  366.0  26.0  101.4  106.4 -4.84  1991  WSB\n4     26  56  317.0  30.0  102.9  107.5 -4.53  1991  NJN\n...   ..  ..    ...   ...    ...    ...   ...   ...  ...\n1028  42  30  583.0   NaN  112.4  110.2  2.26  2021  DAL\n1029  38  34  528.0   4.0  113.3  112.3  1.07  2021  MEM\n1030  33  39  458.0   9.0  111.1  112.8 -1.58  2021  SAS\n1031  31  41  431.0  11.0  114.6  114.9 -0.20  2021  NOP\n1032  17  55  236.0  25.0  108.8  116.7 -7.50  2021  HOU\n\n[906 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n      <th>Year</th>\n      <th>Team</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>26</td>\n      <td>683.0</td>\n      <td>NaN</td>\n      <td>111.5</td>\n      <td>105.7</td>\n      <td>5.22</td>\n      <td>1991</td>\n      <td>BOS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44</td>\n      <td>38</td>\n      <td>537.0</td>\n      <td>12.0</td>\n      <td>105.4</td>\n      <td>105.6</td>\n      <td>-0.39</td>\n      <td>1991</td>\n      <td>PHI</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39</td>\n      <td>43</td>\n      <td>476.0</td>\n      <td>17.0</td>\n      <td>103.1</td>\n      <td>103.3</td>\n      <td>-0.43</td>\n      <td>1991</td>\n      <td>NYK</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30</td>\n      <td>52</td>\n      <td>366.0</td>\n      <td>26.0</td>\n      <td>101.4</td>\n      <td>106.4</td>\n      <td>-4.84</td>\n      <td>1991</td>\n      <td>WSB</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26</td>\n      <td>56</td>\n      <td>317.0</td>\n      <td>30.0</td>\n      <td>102.9</td>\n      <td>107.5</td>\n      <td>-4.53</td>\n      <td>1991</td>\n      <td>NJN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1028</th>\n      <td>42</td>\n      <td>30</td>\n      <td>583.0</td>\n      <td>NaN</td>\n      <td>112.4</td>\n      <td>110.2</td>\n      <td>2.26</td>\n      <td>2021</td>\n      <td>DAL</td>\n    </tr>\n    <tr>\n      <th>1029</th>\n      <td>38</td>\n      <td>34</td>\n      <td>528.0</td>\n      <td>4.0</td>\n      <td>113.3</td>\n      <td>112.3</td>\n      <td>1.07</td>\n      <td>2021</td>\n      <td>MEM</td>\n    </tr>\n    <tr>\n      <th>1030</th>\n      <td>33</td>\n      <td>39</td>\n      <td>458.0</td>\n      <td>9.0</td>\n      <td>111.1</td>\n      <td>112.8</td>\n      <td>-1.58</td>\n      <td>2021</td>\n      <td>SAS</td>\n    </tr>\n    <tr>\n      <th>1031</th>\n      <td>31</td>\n      <td>41</td>\n      <td>431.0</td>\n      <td>11.0</td>\n      <td>114.6</td>\n      <td>114.9</td>\n      <td>-0.20</td>\n      <td>2021</td>\n      <td>NOP</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>17</td>\n      <td>55</td>\n      <td>236.0</td>\n      <td>25.0</td>\n      <td>108.8</td>\n      <td>116.7</td>\n      <td>-7.50</td>\n      <td>2021</td>\n      <td>HOU</td>\n    </tr>\n  </tbody>\n</table>\n<p>906 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_2b = cleaning_teamsdf_removeUnimportantRows(teams_2b)\n",
    "teams_2b = cleaning_teamsdf_convertStripToNan(teams_2b)\n",
    "teams_2b = cleaning_teamsdf_convertToAppropriateDatatype(teams_2b)\n",
    "teams_2b = cleaning_anyDf_removeStarInTeamName(teams_2b)\n",
    "teams_2b = cleaning_anyDf_convertTeamNamesToItsAbbrev(teams_2b, nicknames_df)\n",
    "teams_2b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def cleaning_inflationDf_separateDateColumns(us_inflation_2b, column='Yearmon', format=\"%d-%m-%Y\"):\n",
    "    us_inflation_2b = us_inflation_2b.copy()\n",
    "\n",
    "    dates = []\n",
    "    for i in range(len(us_inflation_2b)):\n",
    "        date = us_inflation_2b[column].iloc[i]\n",
    "        date = datetime.strptime(date, format)\n",
    "        dates.append(date)\n",
    "    us_inflation_2b['Year']  = [date.year for date in dates]\n",
    "    us_inflation_2b['Month'] = [date.month for date in dates]\n",
    "    us_inflation_2b['Day']   = [date.day for date in dates]\n",
    "\n",
    "    return us_inflation_2b\n",
    "\n",
    "\n",
    "def cleaning_inflationDf_getYearByMedian(us_inflation_2b):\n",
    "    \"\"\"\n",
    "    precondition: cleaning_inflationDf_separateDateColumns\n",
    "    \"\"\"\n",
    "    us_inflation_2b = us_inflation_2b.copy()\n",
    "    us_inflation_2b = cleaning_inflationDf_separateDateColumns(us_inflation_2b)\n",
    "    us_inflation_2b = us_inflation_2b.groupby(by='Year')['CPI'].median()\n",
    "    us_inflation_2b = us_inflation_2b.reset_index()\n",
    "    return us_inflation_2b\n",
    "\n",
    "\n",
    "def cleaning_anyDf_removeDuplicatedColumns(combined_df):\n",
    "    combined_df = combined_df.copy()\n",
    "    columns = combined_df.columns\n",
    "\n",
    "    columns_tobe_removed = []\n",
    "    for i in range(len(columns)):\n",
    "        col1 = columns[i]\n",
    "        for j in range(i+1, len(columns)):\n",
    "            col2 = columns[j]\n",
    "\n",
    "            if (combined_df[col1] == combined_df[col2]).all():\n",
    "                columns_tobe_removed.append(col1)\n",
    "    columns_tobe_kept = set(combined_df.columns) - set(columns_tobe_removed)\n",
    "    columns_tobe_kept = list(columns_tobe_kept)\n",
    "    return combined_df.loc[:, columns_tobe_kept]\n",
    "\n",
    "def cleaning_anyDf_recalculateWLpercentage(teams_2b):\n",
    "    teams_2b = teams_2b.copy()\n",
    "    teams_2b['W/L%'] = 100*teams_2b.W / (teams_2b.W + teams_2b.L)\n",
    "    return teams_2b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      Yearmon  CPI\n0  01-01-1913  9.8\n1  01-02-1913  9.8\n2  01-03-1913  9.8\n3  01-04-1913  9.8\n4  01-05-1913  9.7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Yearmon</th>\n      <th>CPI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01-01-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01-02-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01-03-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01-04-1913</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01-05-1913</td>\n      <td>9.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_inflation_2b.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "     Year       CPI\n0    1913    9.8500\n1    1914   10.0000\n2    1915   10.1000\n3    1916   10.8000\n4    1917   12.9000\n..    ...       ...\n104  2017  244.8705\n105  2018  251.7885\n106  2019  256.3505\n107  2020  258.8895\n108  2021  267.0540\n\n[109 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>CPI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1913</td>\n      <td>9.8500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1914</td>\n      <td>10.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1915</td>\n      <td>10.1000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1916</td>\n      <td>10.8000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1917</td>\n      <td>12.9000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>2017</td>\n      <td>244.8705</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>2018</td>\n      <td>251.7885</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>2019</td>\n      <td>256.3505</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>2020</td>\n      <td>258.8895</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>2021</td>\n      <td>267.0540</td>\n    </tr>\n  </tbody>\n</table>\n<p>109 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_inflationDf_getYearByMedian(cleaning_inflationDf_separateDateColumns(us_inflation_2b))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pada kasus ini kami memutuskan mengambil median dari inflasi karena CPI merupakan perbandingan inflasi pada tahun ini dengan inflasi pada suatu tahun yang dijadikan pivot. Karena CPI merupakan suatu perbandingan, maka kami merasa bahwa mengambil median lebih tepat dibandingkan mengambil mean-nya."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "us_inflation_2b_cleaned = us_inflation_2b.copy()\n",
    "us_inflation_2b_cleaned = cleaning_inflationDf_separateDateColumns(us_inflation_2b_cleaned)\n",
    "us_inflation_2b_cleaned = cleaning_inflationDf_getYearByMedian(us_inflation_2b_cleaned)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   Year    CPI   W   L       W/L%    GB   PS/G   PA/G   SRS Team\n0  1991  136.1  56  26  68.292683   NaN  111.5  105.7  5.22  BOS\n1  1991  136.1  44  38  53.658537  12.0  105.4  105.6 -0.39  PHI\n2  1991  136.1  39  43  47.560976  17.0  103.1  103.3 -0.43  NYK",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>CPI</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n      <th>Team</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>56</td>\n      <td>26</td>\n      <td>68.292683</td>\n      <td>NaN</td>\n      <td>111.5</td>\n      <td>105.7</td>\n      <td>5.22</td>\n      <td>BOS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>44</td>\n      <td>38</td>\n      <td>53.658537</td>\n      <td>12.0</td>\n      <td>105.4</td>\n      <td>105.6</td>\n      <td>-0.39</td>\n      <td>PHI</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>39</td>\n      <td>43</td>\n      <td>47.560976</td>\n      <td>17.0</td>\n      <td>103.1</td>\n      <td>103.3</td>\n      <td>-0.43</td>\n      <td>NYK</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = us_inflation_2b_cleaned.merge(teams_2b, left_on=[\"Year\"], right_on=[\"Year\"])\n",
    "combined_df = cleaning_anyDf_recalculateWLpercentage(combined_df)\n",
    "combined_df.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "mvp_stats_2b = mvp_stats_2b.drop('Tm', axis=1)  # karena sudah ada kolom Team\n",
    "mvp_stats_2b = cleaning_anyDf_convertTeamNamesToItsAbbrev(mvp_stats_2b, nicknames_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "        Player Pos  Age   G  GS    MP   FG   FGA    FG%   3P  ...  Pts Max  \\\n0   A.C. Green  PF   27  82  21  26.4  3.1   6.6  476.0  0.1  ...        0   \n1  Byron Scott  SG   29  82  82  32.1  6.1  12.8  477.0  0.9  ...        0   \n\n   Share  Team   W   L   W/L%   GB   PS/G  PA/G   SRS  \n0    0.0   LAL  58  24  707.0  5.0  106.3  99.6  6.73  \n1    0.0   LAL  58  24  707.0  5.0  106.3  99.6  6.73  \n\n[2 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Player</th>\n      <th>Pos</th>\n      <th>Age</th>\n      <th>G</th>\n      <th>GS</th>\n      <th>MP</th>\n      <th>FG</th>\n      <th>FGA</th>\n      <th>FG%</th>\n      <th>3P</th>\n      <th>...</th>\n      <th>Pts Max</th>\n      <th>Share</th>\n      <th>Team</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A.C. Green</td>\n      <td>PF</td>\n      <td>27</td>\n      <td>82</td>\n      <td>21</td>\n      <td>26.4</td>\n      <td>3.1</td>\n      <td>6.6</td>\n      <td>476.0</td>\n      <td>0.1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>LAL</td>\n      <td>58</td>\n      <td>24</td>\n      <td>707.0</td>\n      <td>5.0</td>\n      <td>106.3</td>\n      <td>99.6</td>\n      <td>6.73</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Byron Scott</td>\n      <td>SG</td>\n      <td>29</td>\n      <td>82</td>\n      <td>82</td>\n      <td>32.1</td>\n      <td>6.1</td>\n      <td>12.8</td>\n      <td>477.0</td>\n      <td>0.9</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>LAL</td>\n      <td>58</td>\n      <td>24</td>\n      <td>707.0</td>\n      <td>5.0</td>\n      <td>106.3</td>\n      <td>99.6</td>\n      <td>6.73</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 40 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   Year    CPI   W   L       W/L%    GB   PS/G   PA/G   SRS Team\n0  1991  136.1  56  26  68.292683   NaN  111.5  105.7  5.22  BOS\n1  1991  136.1  44  38  53.658537  12.0  105.4  105.6 -0.39  PHI",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>CPI</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>PS/G</th>\n      <th>PA/G</th>\n      <th>SRS</th>\n      <th>Team</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>56</td>\n      <td>26</td>\n      <td>68.292683</td>\n      <td>NaN</td>\n      <td>111.5</td>\n      <td>105.7</td>\n      <td>5.22</td>\n      <td>BOS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1991</td>\n      <td>136.1</td>\n      <td>44</td>\n      <td>38</td>\n      <td>53.658537</td>\n      <td>12.0</td>\n      <td>105.4</td>\n      <td>105.6</td>\n      <td>-0.39</td>\n      <td>PHI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyaknya null salaries:  28074\n",
      "banyaknya null player name salaries:  0\n",
      "banyaknya null player name mvp stats:  0\n",
      "banyaknya null team name:  0\n",
      "\n",
      "banyaknya row salaries df :  37420\n",
      "banyaknya row mvp statsdf :  14092\n",
      "banyaknya row combined df :  906\n"
     ]
    }
   ],
   "source": [
    "display(mvp_stats_2b.head(2))\n",
    "display(combined_df.head(2))\n",
    "print('banyaknya null salaries: ', salaries_2b.Salaries.isna().sum())\n",
    "print('banyaknya null player name salaries: ', salaries_2b.Name.isna().sum())\n",
    "print('banyaknya null player name mvp stats: ', mvp_stats_2b.Player.isna().sum())\n",
    "print('banyaknya null team name: ', combined_df.Team.isna().sum())\n",
    "print()\n",
    "print('banyaknya row salaries df : ', len(salaries_2b))\n",
    "print('banyaknya row mvp statsdf : ', len(mvp_stats_2b))\n",
    "print('banyaknya row combined df : ', len(combined_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   Pts Won    CPI   TRB     W/L%_y   2PA    2P%            Player  W_y   PTS  \\\n0     1207  172.6  13.6  81.707317  21.1  575.0  Shaquille O'Neal   67  29.7   \n1      408  172.6  11.8  60.975610  17.8  504.0     Kevin Garnett   50  22.9   \n2      367  172.6   9.5  63.414634  14.9  553.0   Alonzo Mourning   52  21.7   \n3        0  172.6   5.7  35.365854  13.4  462.0      Juwan Howard   29  14.9   \n4        0  172.6   6.3  71.951220   7.3  506.0    Scottie Pippen   59  12.5   \n\n   ORB  ...    FG%   PF  AST  DRB  GS  GB_x  L_y  PS/G_y  STL  W/L%_x  \n0  4.3  ...  574.0  3.2  3.8  9.4  79   0.0   15   100.8  0.5  817.00  \n1  2.8  ...  497.0  2.5  5.0  9.0  81   5.0   32    98.5  1.5    0.61  \n2  2.7  ...  551.0  3.9  1.6  6.8  78   0.0   30    94.4  0.5  634.00  \n3  1.6  ...  459.0  3.6  3.0  4.1  82  23.0   53    96.6  0.8  354.00  \n4  1.4  ...  451.0  2.5  5.0  4.9  82   8.0   23    97.5  1.4    0.72  \n\n[5 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pts Won</th>\n      <th>CPI</th>\n      <th>TRB</th>\n      <th>W/L%_y</th>\n      <th>2PA</th>\n      <th>2P%</th>\n      <th>Player</th>\n      <th>W_y</th>\n      <th>PTS</th>\n      <th>ORB</th>\n      <th>...</th>\n      <th>FG%</th>\n      <th>PF</th>\n      <th>AST</th>\n      <th>DRB</th>\n      <th>GS</th>\n      <th>GB_x</th>\n      <th>L_y</th>\n      <th>PS/G_y</th>\n      <th>STL</th>\n      <th>W/L%_x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1207</td>\n      <td>172.6</td>\n      <td>13.6</td>\n      <td>81.707317</td>\n      <td>21.1</td>\n      <td>575.0</td>\n      <td>Shaquille O'Neal</td>\n      <td>67</td>\n      <td>29.7</td>\n      <td>4.3</td>\n      <td>...</td>\n      <td>574.0</td>\n      <td>3.2</td>\n      <td>3.8</td>\n      <td>9.4</td>\n      <td>79</td>\n      <td>0.0</td>\n      <td>15</td>\n      <td>100.8</td>\n      <td>0.5</td>\n      <td>817.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>408</td>\n      <td>172.6</td>\n      <td>11.8</td>\n      <td>60.975610</td>\n      <td>17.8</td>\n      <td>504.0</td>\n      <td>Kevin Garnett</td>\n      <td>50</td>\n      <td>22.9</td>\n      <td>2.8</td>\n      <td>...</td>\n      <td>497.0</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>81</td>\n      <td>5.0</td>\n      <td>32</td>\n      <td>98.5</td>\n      <td>1.5</td>\n      <td>0.61</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>367</td>\n      <td>172.6</td>\n      <td>9.5</td>\n      <td>63.414634</td>\n      <td>14.9</td>\n      <td>553.0</td>\n      <td>Alonzo Mourning</td>\n      <td>52</td>\n      <td>21.7</td>\n      <td>2.7</td>\n      <td>...</td>\n      <td>551.0</td>\n      <td>3.9</td>\n      <td>1.6</td>\n      <td>6.8</td>\n      <td>78</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>94.4</td>\n      <td>0.5</td>\n      <td>634.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>172.6</td>\n      <td>5.7</td>\n      <td>35.365854</td>\n      <td>13.4</td>\n      <td>462.0</td>\n      <td>Juwan Howard</td>\n      <td>29</td>\n      <td>14.9</td>\n      <td>1.6</td>\n      <td>...</td>\n      <td>459.0</td>\n      <td>3.6</td>\n      <td>3.0</td>\n      <td>4.1</td>\n      <td>82</td>\n      <td>23.0</td>\n      <td>53</td>\n      <td>96.6</td>\n      <td>0.8</td>\n      <td>354.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>172.6</td>\n      <td>6.3</td>\n      <td>71.951220</td>\n      <td>7.3</td>\n      <td>506.0</td>\n      <td>Scottie Pippen</td>\n      <td>59</td>\n      <td>12.5</td>\n      <td>1.4</td>\n      <td>...</td>\n      <td>451.0</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>4.9</td>\n      <td>82</td>\n      <td>8.0</td>\n      <td>23</td>\n      <td>97.5</td>\n      <td>1.4</td>\n      <td>0.72</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 45 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_2b = salaries_2b[[\"Name\", \"Year\", \"Salaries\", \"Rank\"]]\n",
    "\n",
    "combined_df = mvp_stats_2b.merge(combined_df, left_on=[\"Team\", \"Year\"], right_on=[\"Team\", \"Year\"])\n",
    "combined_df = salaries_2b.merge(combined_df, left_on=[\"Name\", \"Year\"], right_on=[\"Player\", \"Year\"])\n",
    "combined_df = cleaning_anyDf_removeDuplicatedColumns(combined_df)\n",
    "\n",
    "combined_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyaknya data duplikat:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Banyaknya data duplikat: \", combined_df.duplicated().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8323 entries, 0 to 8322\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pts Won   8323 non-null   int64  \n",
      " 1   CPI       8323 non-null   float64\n",
      " 2   TRB       8323 non-null   float64\n",
      " 3   W/L%_y    8323 non-null   float64\n",
      " 4   2PA       8323 non-null   float64\n",
      " 5   2P%       8276 non-null   float64\n",
      " 6   Player    8323 non-null   object \n",
      " 7   W_y       8323 non-null   int64  \n",
      " 8   PTS       8323 non-null   float64\n",
      " 9   ORB       8323 non-null   float64\n",
      " 10  Team      8323 non-null   object \n",
      " 11  PA/G_y    8323 non-null   float64\n",
      " 12  FGA       8323 non-null   float64\n",
      " 13  MP        8323 non-null   float64\n",
      " 14  Year      8323 non-null   int64  \n",
      " 15  FG        8323 non-null   float64\n",
      " 16  3P%       7118 non-null   float64\n",
      " 17  TOV       8323 non-null   float64\n",
      " 18  Salaries  7933 non-null   float64\n",
      " 19  eFG%      8296 non-null   float64\n",
      " 20  Pts Max   8323 non-null   int64  \n",
      " 21  SRS_y     8323 non-null   float64\n",
      " 22  3P        8323 non-null   float64\n",
      " 23  FT%       8066 non-null   float64\n",
      " 24  FTA       8323 non-null   float64\n",
      " 25  Share     8323 non-null   float64\n",
      " 26  Age       8323 non-null   int64  \n",
      " 27  G         8323 non-null   int64  \n",
      " 28  BLK       8323 non-null   float64\n",
      " 29  3PA       8323 non-null   float64\n",
      " 30  2P        8323 non-null   float64\n",
      " 31  Rank      8323 non-null   int64  \n",
      " 32  Pos       8323 non-null   object \n",
      " 33  FT        8323 non-null   float64\n",
      " 34  GB_y      6705 non-null   float64\n",
      " 35  FG%       8296 non-null   float64\n",
      " 36  PF        8323 non-null   float64\n",
      " 37  AST       8323 non-null   float64\n",
      " 38  DRB       8323 non-null   float64\n",
      " 39  GS        8323 non-null   int64  \n",
      " 40  GB_x      8323 non-null   float64\n",
      " 41  L_y       8323 non-null   int64  \n",
      " 42  PS/G_y    8323 non-null   float64\n",
      " 43  STL       8323 non-null   float64\n",
      " 44  W/L%_x    8323 non-null   float64\n",
      "dtypes: float64(33), int64(9), object(3)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Drop missing values pada target feature\n",
    "\n",
    "kami memutuskan untuk mendrop missing values pada target feature karena target feature merupakan ground truth. Oleh karena itu, kami tidak setuju apabila kita melakukan imputasi untuk missing values pada kolom ini. Sebab, apabila kita melakukan imputasi terhadap missing values untuk kolom ini, maka kolom ini tidak sepenuhnya menjadi ground truth lagi karena diisikan dengan data-data sintesis yang tidak diketahui kebenarannya."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyak missing values pada kolom Salaries:  390\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pts Won        0\nCPI            0\nTRB            0\nW/L%_y         0\n2PA            0\n2P%           43\nPlayer         0\nW_y            0\nPTS            0\nORB            0\nTeam           0\nPA/G_y         0\nFGA            0\nMP             0\nYear           0\nFG             0\n3P%         1117\nTOV            0\nSalaries       0\neFG%          25\nPts Max        0\nSRS_y          0\n3P             0\nFT%          230\nFTA            0\nShare          0\nAge            0\nG              0\nBLK            0\n3PA            0\n2P             0\nRank           0\nPos            0\nFT             0\nGB_y        1571\nFG%           25\nPF             0\nAST            0\nDRB            0\nGS             0\nGB_x           0\nL_y            0\nPS/G_y         0\nSTL            0\nW/L%_x         0\ndtype: int64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Banyak missing values pada kolom Salaries: \", combined_df.Salaries.isna().sum())\n",
    "combined_df = combined_df[combined_df.Salaries.notna()]\n",
    "combined_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Memisahkan kolom-kolom menjadi feature (X) dan target (y) dan drop fitur-fitur yang tidak diperlukan\n",
    "\n",
    "Pada dataset ini, kita sudah memiliki gabungan seluruh feature mengenai statistik performa team dan statistik performa pemain. Oleh karena itu, nama tim dan nama pemain sudah tidak lagi berkaitan dengan gaji yang diperoleh. Nama tim sudah dapat digantikan dengan data mengenai performa tim, dan nama pemain dapat digantikan dengan data mengenai performa pemain.\n",
    "\n",
    "Sementara itu, kita melakukan drop kolom Rank karena kolom tersebut merupakan Ranking gaji seorang pemain pada tahun itu. Oleh karena itu, kami merasa informasi ini tidak valid untuk dijadikan dasar dalam memprediksi gaji pemain."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   Pts Won    CPI   TRB     W/L%_y   2PA    2P%  W_y   PTS  ORB  PA/G_y  ...  \\\n0     1207  172.6  13.6  81.707317  21.1  575.0   67  29.7  4.3    92.3  ...   \n1      408  172.6  11.8  60.975610  17.8  504.0   50  22.9  2.8    96.0  ...   \n\n     FG%   PF  AST  DRB  GS  GB_x  L_y  PS/G_y  STL  W/L%_x  \n0  574.0  3.2  3.8  9.4  79   0.0   15   100.8  0.5  817.00  \n1  497.0  2.5  5.0  9.0  81   5.0   32    98.5  1.5    0.61  \n\n[2 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pts Won</th>\n      <th>CPI</th>\n      <th>TRB</th>\n      <th>W/L%_y</th>\n      <th>2PA</th>\n      <th>2P%</th>\n      <th>W_y</th>\n      <th>PTS</th>\n      <th>ORB</th>\n      <th>PA/G_y</th>\n      <th>...</th>\n      <th>FG%</th>\n      <th>PF</th>\n      <th>AST</th>\n      <th>DRB</th>\n      <th>GS</th>\n      <th>GB_x</th>\n      <th>L_y</th>\n      <th>PS/G_y</th>\n      <th>STL</th>\n      <th>W/L%_x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1207</td>\n      <td>172.6</td>\n      <td>13.6</td>\n      <td>81.707317</td>\n      <td>21.1</td>\n      <td>575.0</td>\n      <td>67</td>\n      <td>29.7</td>\n      <td>4.3</td>\n      <td>92.3</td>\n      <td>...</td>\n      <td>574.0</td>\n      <td>3.2</td>\n      <td>3.8</td>\n      <td>9.4</td>\n      <td>79</td>\n      <td>0.0</td>\n      <td>15</td>\n      <td>100.8</td>\n      <td>0.5</td>\n      <td>817.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>408</td>\n      <td>172.6</td>\n      <td>11.8</td>\n      <td>60.975610</td>\n      <td>17.8</td>\n      <td>504.0</td>\n      <td>50</td>\n      <td>22.9</td>\n      <td>2.8</td>\n      <td>96.0</td>\n      <td>...</td>\n      <td>497.0</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>81</td>\n      <td>5.0</td>\n      <td>32</td>\n      <td>98.5</td>\n      <td>1.5</td>\n      <td>0.61</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 41 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "     Salaries\n0  17142000.0\n1  16806000.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Salaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17142000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16806000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_2b, y_2b = combined_df.drop(\"Salaries\", axis=1), combined_df[[\"Salaries\"]]\n",
    "x_2b.drop(\"Team\", axis=1, inplace=True)\n",
    "x_2b.drop(\"Player\", axis=1, inplace=True)\n",
    "x_2b.drop(\"Rank\", axis=1, inplace=True)\n",
    "\n",
    "display(x_2b.head(2))\n",
    "display(y_2b.head(2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B. Membagi dataset menjadi training, testing, dan final testing\n",
    "\n",
    "Kami memutuskan untuk membagi dataset menjadi training, testing, dan final testing. Dataset final testing diperlukan karena kita sangat disarankan untuk memasuki fase testing hanya sekali saja, yakni ketika kita sudah benar-benar yakin dengan model yang kita bangun dan sudah tidak ingin mengutak-atik modelnya lagi. Oleh karena itu, kami memutuskan untuk membagi dataset testing menjadi testing untuk mengecek performa, dan final testing untuk model yang sudah final."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "x_2b_train, x2b_final_test, y_2b_train, y_2b_final_test = train_test_split(\n",
    "    x_2b, y_2b, test_size=0.2, random_state=random_state\n",
    ")\n",
    "del x_2b\n",
    "del y_2b\n",
    "\n",
    "x_2b_train, x2b_test, y_2b_train, y_2b_test = train_test_split(\n",
    "    x_2b_train, y_2b_train, test_size=0.2, random_state=random_state,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B training model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class Alternative(TransformerMixin):\n",
    "    def __init__(self, *models, curr_model=0):\n",
    "        self.__curr_model = curr_model\n",
    "        self.models = models\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.get_curr_model().fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.get_curr_model().predict(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        res = self.get_curr_model().transform(X)\n",
    "        return res\n",
    "\n",
    "    def set_curr_model(self, model_index: int):\n",
    "        self.__curr_model = model_index\n",
    "\n",
    "    def get_curr_model(self):\n",
    "        return self.models[self.__curr_model]\n",
    "\n",
    "    def set_params(self, **kwargs):\n",
    "        if 'curr_model' in kwargs:\n",
    "            self.set_curr_model(kwargs['curr_model'])\n",
    "            del kwargs['curr_model']\n",
    "        self.get_curr_model().set_params(**kwargs)\n",
    "        return self\n",
    "\n",
    "def cartesian_product_of_dict_lists(*multiple_list_of_dicts):\n",
    "    if len(multiple_list_of_dicts) == 0:\n",
    "        return []\n",
    "\n",
    "    if len(multiple_list_of_dicts) == 1:\n",
    "        return multiple_list_of_dicts[0]\n",
    "\n",
    "    if len(multiple_list_of_dicts) == 2:\n",
    "        ret = []\n",
    "        for dict1 in multiple_list_of_dicts[0]:\n",
    "            for dict2 in multiple_list_of_dicts[1]:\n",
    "                ret.append(dict(**dict1, **dict2))\n",
    "        return ret\n",
    "\n",
    "    curr = [{}]\n",
    "    for dct in multiple_list_of_dicts:\n",
    "        curr = cartesian_product_of_dict_lists(curr, dct)\n",
    "    return curr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin #gives fit_transform method for free\n",
    "\n",
    "# LabelEncoder tidak dapat dimasukkan ke dalam pipeline karena\n",
    "# LabelEncoder.transform() tidak memiliki parameter y\n",
    "\n",
    "class MyLabelEncoder(TransformerMixin):\n",
    "    # source: https://stackoverflow.com/a/46619402/7069108\n",
    "    def __init__(self, columns_to_be_encoded: list[str], *args, **kwargs):\n",
    "        self.columns_to_be_encoded = columns_to_be_encoded\n",
    "        self.encoder = preprocessing.LabelEncoder(*args, **kwargs)\n",
    "\n",
    "    def fit(self, x, y=0):\n",
    "        for col in self.columns_to_be_encoded:\n",
    "            self.encoder.fit(x[col])\n",
    "        return self\n",
    "\n",
    "    def transform(self, x, y=0):\n",
    "        x = x.copy()\n",
    "        for col in self.columns_to_be_encoded:\n",
    "            x[col] = self.encoder.transform(x[col])\n",
    "        return x\n",
    "\n",
    "label_encoder = MyLabelEncoder([\"Pos\"])\n",
    "label_encoder_params = [{}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "scaler1 = preprocessing.MinMaxScaler()\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "scaler3 = preprocessing.RobustScaler()\n",
    "\n",
    "scaler = Alternative(\n",
    "    scaler1, scaler2, scaler3\n",
    ")\n",
    "\n",
    "scaler_params = [{\n",
    "    'scaler__curr_model': [0, 1, 2]\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "imputer1 = SimpleImputer()\n",
    "imputer2 = KNNImputer()\n",
    "\n",
    "imputer = Alternative(\n",
    "    imputer1, imputer2,\n",
    ")\n",
    "\n",
    "imputer_params = [{\n",
    "    'imputer__curr_model': [0, 1]\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "feature_selector1 = SelectFromModel(estimator=Lasso())\n",
    "feature_selector2 = SelectKBest()\n",
    "\n",
    "feature_selector = Alternative(\n",
    "    feature_selector2,\n",
    "    feature_selector1\n",
    ")\n",
    "\n",
    "feature_selector_params = [{\n",
    "    'feature_selector__curr_model': [1],\n",
    "    'feature_selector__estimator__alpha': [0.01, 0.005, 0.0005]\n",
    "}, {\n",
    "    'feature_selector__curr_model': [0],\n",
    "    'feature_selector__k': [7, 8, 9],\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "predictors  = Alternative(\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(),\n",
    ")\n",
    "\n",
    "predictor_params = [{\n",
    "    'predictor__curr_model': [0, 1]\n",
    "}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('encoding', label_encoder),\n",
    "        ('scaler', scaler),\n",
    "        ('imputer', imputer),\n",
    "        ('feature_selector', feature_selector),\n",
    "        ('predictor', predictors),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "grid_params = cartesian_product_of_dict_lists(\n",
    "    label_encoder_params,\n",
    "    scaler_params,\n",
    "    imputer_params,\n",
    "    feature_selector_params,\n",
    "    predictor_params\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\01 Kuliah\\01 Dokumen\\52 - KASDD\\proyek-akhir\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "H:\\01 Kuliah\\01 Dokumen\\52 - KASDD\\proyek-akhir\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.139e+16, tolerance: 1.397e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=Pipeline(steps=[('encoding',\n                                        <__main__.MyLabelEncoder object at 0x000002A7773C7580>),\n                                       ('scaler',\n                                        <__main__.Alternative object at 0x000002A7773C4550>),\n                                       ('imputer',\n                                        <__main__.Alternative object at 0x000002A7773C7130>),\n                                       ('feature_selector',\n                                        <__main__.Alternative object at 0x000002A7773C7DF0>),\n                                       ('predictor',\n                                        <__main__.Alternative object at 0x000002A7773...\n             param_grid=[{'feature_selector__curr_model': [1],\n                          'feature_selector__estimator__alpha': [0.01, 0.005,\n                                                                 0.0005],\n                          'imputer__curr_model': [0, 1],\n                          'predictor__curr_model': [0, 1],\n                          'scaler__curr_model': [0, 1, 2]},\n                         {'feature_selector__curr_model': [0],\n                          'feature_selector__k': [7, 8, 9],\n                          'imputer__curr_model': [0, 1],\n                          'predictor__curr_model': [0, 1],\n                          'scaler__curr_model': [0, 1, 2]}],\n             scoring='neg_mean_absolute_error')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;encoding&#x27;,\n                                        &lt;__main__.MyLabelEncoder object at 0x000002A7773C7580&gt;),\n                                       (&#x27;scaler&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773C4550&gt;),\n                                       (&#x27;imputer&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773C7130&gt;),\n                                       (&#x27;feature_selector&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773C7DF0&gt;),\n                                       (&#x27;predictor&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773...\n             param_grid=[{&#x27;feature_selector__curr_model&#x27;: [1],\n                          &#x27;feature_selector__estimator__alpha&#x27;: [0.01, 0.005,\n                                                                 0.0005],\n                          &#x27;imputer__curr_model&#x27;: [0, 1],\n                          &#x27;predictor__curr_model&#x27;: [0, 1],\n                          &#x27;scaler__curr_model&#x27;: [0, 1, 2]},\n                         {&#x27;feature_selector__curr_model&#x27;: [0],\n                          &#x27;feature_selector__k&#x27;: [7, 8, 9],\n                          &#x27;imputer__curr_model&#x27;: [0, 1],\n                          &#x27;predictor__curr_model&#x27;: [0, 1],\n                          &#x27;scaler__curr_model&#x27;: [0, 1, 2]}],\n             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;encoding&#x27;,\n                                        &lt;__main__.MyLabelEncoder object at 0x000002A7773C7580&gt;),\n                                       (&#x27;scaler&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773C4550&gt;),\n                                       (&#x27;imputer&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773C7130&gt;),\n                                       (&#x27;feature_selector&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773C7DF0&gt;),\n                                       (&#x27;predictor&#x27;,\n                                        &lt;__main__.Alternative object at 0x000002A7773...\n             param_grid=[{&#x27;feature_selector__curr_model&#x27;: [1],\n                          &#x27;feature_selector__estimator__alpha&#x27;: [0.01, 0.005,\n                                                                 0.0005],\n                          &#x27;imputer__curr_model&#x27;: [0, 1],\n                          &#x27;predictor__curr_model&#x27;: [0, 1],\n                          &#x27;scaler__curr_model&#x27;: [0, 1, 2]},\n                         {&#x27;feature_selector__curr_model&#x27;: [0],\n                          &#x27;feature_selector__k&#x27;: [7, 8, 9],\n                          &#x27;imputer__curr_model&#x27;: [0, 1],\n                          &#x27;predictor__curr_model&#x27;: [0, 1],\n                          &#x27;scaler__curr_model&#x27;: [0, 1, 2]}],\n             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;encoding&#x27;,\n                 &lt;__main__.MyLabelEncoder object at 0x000002A7773C7580&gt;),\n                (&#x27;scaler&#x27;, &lt;__main__.Alternative object at 0x000002A7773C4550&gt;),\n                (&#x27;imputer&#x27;,\n                 &lt;__main__.Alternative object at 0x000002A7773C7130&gt;),\n                (&#x27;feature_selector&#x27;,\n                 &lt;__main__.Alternative object at 0x000002A7773C7DF0&gt;),\n                (&#x27;predictor&#x27;,\n                 &lt;__main__.Alternative object at 0x000002A7773C4940&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MyLabelEncoder</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.MyLabelEncoder object at 0x000002A7773C7580&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Alternative</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Alternative object at 0x000002A7773C4550&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Alternative</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Alternative object at 0x000002A7773C7130&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Alternative</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Alternative object at 0x000002A7773C7DF0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Alternative</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Alternative object at 0x000002A7773C4940&gt;</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=grid_params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search_cv.fit(x_2b_train, y_2b_train.Salaries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2B testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rata-rata error absolut:  2502435.80484669\n",
      "Rata-rata error relatif:  0.5432521005553796\n"
     ]
    }
   ],
   "source": [
    "y_2b_predict = grid_search_cv.predict(x2b_test)\n",
    "mae = metrics.mean_absolute_error(y_2b_test, y_2b_predict)\n",
    "print(\"Rata-rata error absolut: \", mae)\n",
    "print(\"Rata-rata error relatif: \", mae / y_2b_test.Salaries.mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'feature_selector__curr_model': 1,\n 'feature_selector__estimator__alpha': 0.01,\n 'imputer__curr_model': 0,\n 'predictor__curr_model': 0,\n 'scaler__curr_model': 0}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SelectKBest instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mgrid_search_cv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_estimator_\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfeature_selector\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_feature_names_out\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_2b_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mH:\\01 Kuliah\\01 Dokumen\\52 - KASDD\\proyek-akhir\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:167\u001B[0m, in \u001B[0;36mSelectorMixin.get_feature_names_out\u001B[1;34m(self, input_features)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03m\"\"\"Mask feature names according to selected features.\u001B[39;00m\n\u001B[0;32m    148\u001B[0m \n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;124;03m    Transformed feature names.\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    166\u001B[0m input_features \u001B[38;5;241m=\u001B[39m _check_feature_names_in(\u001B[38;5;28mself\u001B[39m, input_features)\n\u001B[1;32m--> 167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m input_features[\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_support\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m]\n",
      "File \u001B[1;32mH:\\01 Kuliah\\01 Dokumen\\52 - KASDD\\proyek-akhir\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:53\u001B[0m, in \u001B[0;36mSelectorMixin.get_support\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_support\u001B[39m(\u001B[38;5;28mself\u001B[39m, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;124;03m    Get a mask, or integer index, of the features selected.\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;124;03m        values are indices into the input feature vector.\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 53\u001B[0m     mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_support_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mask \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m indices \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mwhere(mask)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mH:\\01 Kuliah\\01 Dokumen\\52 - KASDD\\proyek-akhir\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:674\u001B[0m, in \u001B[0;36mSelectKBest._get_support_mask\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_support_mask\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 674\u001B[0m     \u001B[43mcheck_is_fitted\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    677\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscores_\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n",
      "File \u001B[1;32mH:\\01 Kuliah\\01 Dokumen\\52 - KASDD\\proyek-akhir\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001B[0m, in \u001B[0;36mcheck_is_fitted\u001B[1;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[0;32m   1340\u001B[0m     fitted \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   1341\u001B[0m         v \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mvars\u001B[39m(estimator) \u001B[38;5;28;01mif\u001B[39;00m v\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m v\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1342\u001B[0m     ]\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fitted:\n\u001B[1;32m-> 1345\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(msg \u001B[38;5;241m%\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(estimator)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m})\n",
      "\u001B[1;31mNotFittedError\u001B[0m: This SelectKBest instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_['feature_selector'].models[0].get_feature_names_out(input_features=x_2b_train.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
